{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "use_gdrive = False\n",
    "retrain_models = False\n",
    "\n",
    "if use_gdrive:\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Directory in Google Drive were we will save data.\n",
    "    BASE_FOLDER = '/content/drive/My Drive/Colab Notebooks/tfm/'\n",
    "    # Just set to True if you want to retrain the models.\n",
    "    retrain_models = False\n",
    "\n",
    "    drive.mount('/content/drive/')\n",
    "else:\n",
    "    BASE_FOLDER = './'\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print('GPU device {} not found'.format(device_name))\n",
    "else:\n",
    "  print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, DepthwiseConv2D\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_width, image_height= 256, 256\n",
    "\n",
    "nb_train_samples= 11000\n",
    "nb_validation_sample=2000\n",
    "batch_size = 8\n",
    "\n",
    "model = applications.MobileNetV2(weights= \"imagenet\", include_top=False, input_shape=(image_height, image_width,3))\n",
    "\n",
    "x=model.layers[7].output\n",
    "#take the first 5 layers of the model\n",
    "x=Flatten()(x)\n",
    "x=Dense(1024, activation=\"relu\")(x)\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(384, activation=\"relu\")(x)\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(96, activation=\"relu\")(x)\n",
    "x=Dropout(0.5)(x)\n",
    "predictions = Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "model_final = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "#model_final = load_model(\"weights_Mobile_Net.h5\")\n",
    "\n",
    "model_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Nadam(lr=0.00001), metrics=[\"accuracy\"])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode=\"nearest\",\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode = \"nearest\",\n",
    "                                  zoom_range = 0.3,\n",
    "                                  width_shift_range = 0.3,\n",
    "                                  height_shift_range=0.3,\n",
    "                                  rotation_range=30)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./train', target_size = (256, 256), batch_size = 8, class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('./validation', target_size = (256, 256), batch_size = 8, class_mode = 'categorical') \n",
    "model_final.fit(training_set, steps_per_epoch = 1000, epochs = 80, validation_data = test_set, validation_steps=1000)\n",
    "print(model.summary())\n",
    "\n",
    "# Save your weights and model.\n",
    "model_json=model_final.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model_final.save_weights(\"weights_VGG.h5\")\n",
    "model_final.save(\"model_27.h5\")\n",
    "#model_final.predict(test_set, batch_size=batch_size)\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"weights_VGG.h5\",by_name=True)\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "#print(loaded_model.summary())\n",
    "loaded_model.fit_generator(training_set, steps_per_epoch = 1000, epochs = 100, validation_data = test_set,validation_steps=1000)\n",
    "#score = loaded_model.evaluate(training_set,test_set , verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/godofpdog/MobileNetV3_keras/blob/master/src/MobileNet_V3.py\n",
    "def __conv2d_block(_inputs, filters, kernel, strides, is_use_bias=False, padding='same', activation='RE', name=None):\n",
    "    x = Conv2D(filters, kernel, strides= strides, padding=padding, use_bias=is_use_bias)(_inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == 'RE':\n",
    "        x = ReLU(name=name)(x)\n",
    "    elif activation == 'HS':\n",
    "        x = Activation(Hswish, name=name)(x)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return x\n",
    "\n",
    "def __depthwise_block(_inputs, kernel=(3, 3), strides=(1, 1), activation='RE', is_use_se=True, num_layers=0):\n",
    "    x = DepthwiseConv2D(kernel_size=kernel, strides=strides, depth_multiplier=1, padding='same', use_bias=False)(_inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    if is_use_se:\n",
    "        x = __se_block(x)\n",
    "    if activation == 'RE':\n",
    "        x = ReLU()(x)\n",
    "    elif activation == 'HS':\n",
    "        x = Activation(Hswish)(x)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return x\n",
    "\n",
    "def __global_depthwise_block(_inputs):\n",
    "    assert _inputs._keras_shape[1] == _inputs._keras_shape[2]\n",
    "    kernel_size = _inputs._keras_shape[1]\n",
    "    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(1, 1), depth_multiplier=1, padding='valid', use_bias=False)(_inputs)\n",
    "    return x\n",
    "\n",
    "def __se_block(_inputs, ratio=4, pooling_type='avg'):\n",
    "    filters = _inputs._keras_shape[-1]\n",
    "    se_shape = (1, 1, filters)\n",
    "    if pooling_type == 'avg':\n",
    "        se = GlobalAveragePooling2D()(_inputs)\n",
    "    elif pooling_type == 'depthwise':\n",
    "        se = __global_depthwise_block(_inputs)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='hard_sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    return multiply([_inputs, se])\n",
    "\n",
    "def __bottleneck_block(_inputs, out_dim, kernel, strides, expansion_dim, is_use_bias=False, shortcut=True, is_use_se=True, activation='RE', num_layers=0, *args):\n",
    "    with tf.name_scope('bottleneck_block'):\n",
    "        # ** to high dim \n",
    "        bottleneck_dim = expansion_dim\n",
    "\n",
    "        # ** pointwise conv \n",
    "        x = __conv2d_block(_inputs, bottleneck_dim, kernel=(1, 1), strides=(1, 1), is_use_bias=is_use_bias, activation=activation)\n",
    "\n",
    "        # ** depthwise conv\n",
    "        x = __depthwise_block(x, kernel=kernel, strides=strides, is_use_se=is_use_se, activation=activation, num_layers=num_layers)\n",
    "\n",
    "        # ** pointwise conv\n",
    "        x = Conv2D(out_dim, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        if shortcut and strides == (1, 1):\n",
    "            in_dim = K.int_shape(_inputs)[-1]\n",
    "            if in_dim != out_dim:\n",
    "                ins = Conv2D(out_dim, (1, 1), strides=(1, 1), padding='same')(_inputs)\n",
    "                x = Add()([x, ins])\n",
    "            else:\n",
    "                x = Add()([x, _inputs])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From LYTNetV2.\n",
    "def make_divisible(x, divisible_by=8):\n",
    "    import numpy as np\n",
    "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layers.\n",
    "def conv_layer(x, filters, kernel_size):\n",
    "    x = layers.Conv2D(filters, kernel_size, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #x = layers.Activation('relu')(x)\n",
    "    x = layers.Activation(tfl.hard_swish)(x)\n",
    "    return x\n",
    "\n",
    "def bottleneck_layer(inputs, output, kernel_size, strides, expansion_dim):\n",
    "    __bottleneck_block(inputs, output, kernel, strides, expansion_dim)\n",
    "\n",
    "# Defining the model.\n",
    "def create_model(height, width, depth):\n",
    "    inputShape = (height, width, depth)\n",
    "    x = layers.Input(shape=input_shape)\n",
    "    x = conv_layer(x, 16, (3, 3))\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    config_list = [\n",
    "        # k, exp, c,  se,     nl,  s,\n",
    "        [3, 16,  16,  False, 'RE', 1],\n",
    "        [3, 64,  24,  False, 'RE', 2],\n",
    "        [3, 72,  24,  False, 'RE', 1],\n",
    "        [5, 72,  40,  True,  'RE', 2],\n",
    "        [5, 120, 40,  True,  'RE', 1],\n",
    "        [3, 240, 80,  False, 'HS', 2],\n",
    "        [3, 200, 80,  False, 'HS', 1],\n",
    "        [3, 480, 112, True,  'HS', 1],\n",
    "        [5, 672, 160, True,  'HS', 2],\n",
    "        [5, 960, 160, True,  'HS', 1],\n",
    "        [3, 960, 320, False,  'RE', 1]\n",
    "    ]\n",
    "    x = bottleneck_layer(x, 24, (3, 3), 1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python\n",
    "\n",
    "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasBatchClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet V2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "number_of_classes = 2\n",
    "BASE_FOLDER = './'\n",
    "retrain_models = False\n",
    "seed = 12\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode=\"nearest\",\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   rotation_range=30)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode = \"nearest\",\n",
    "                                  zoom_range = 0.3,\n",
    "                                  width_shift_range = 0.3,\n",
    "                                  height_shift_range=0.3,\n",
    "                                  rotation_range=30)\n",
    "\n",
    "training_flow = train_datagen.flow_from_directory('./train', target_size = (128, 128), batch_size = 1, class_mode = 'categorical')\n",
    "validation_flow = validation_datagen.flow_from_directory('./validation', target_size = (128, 128), batch_size = 1, class_mode = 'categorical')\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "batch_index = 0\n",
    "while batch_index <= training_flow.batch_index:\n",
    "    data = training_flow.next()\n",
    "    X.append(data[0][0])\n",
    "    Y.append(data[1][0])\n",
    "    batch_index = batch_index + 1\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "print(np.shape(X))\n",
    "sample = X[0]\n",
    "print(Y[0])\n",
    "\n",
    "# show image\n",
    "imgplot = plt.imshow(sample)\n",
    "plt.show()\n",
    "\n",
    "# Split dataset, 90% train and 10% test.\n",
    "split_1 = int(0.9 * len(X))\n",
    "\n",
    "x_train = X[:split_1]\n",
    "y_train = Y[:split_1]\n",
    "x_test = X[split_1:]\n",
    "y_test = Y[split_1:]\n",
    "\n",
    "def add_top_model(base_model, number_of_classes, print_summary=False):\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(number_of_classes, activation='softmax'))\n",
    "    if print_summary:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "# Create model.\n",
    "model_name = 'mobilnet_v2'\n",
    "base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False)\n",
    "base_model.trainable = True\n",
    "model = add_top_model(base_model, number_of_classes, False)\n",
    "model.compile(metrics=['accuracy'], loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "neural_network = KerasClassifier(build_fn=model, \n",
    "                                 epochs=150, \n",
    "                                 batch_size=10, \n",
    "                                 verbose=0)\n",
    "# Evaluate neural network using three-fold cross-validation\n",
    "#accuracies = cross_val_score(neural_network, X, Y, scoring = \"accuracy\", n_jobs = 1)\n",
    "#mean = accuracies.mean()\n",
    "#variance = accuracies.std()\n",
    "\n",
    "# Save checkpoints to get the best weights from all epochs, same name for all, to keep the best checkpoint.\n",
    "filename = BASE_FOLDER+model_name+'checkpoint.hdf5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# Fit model.\n",
    "if retrain_models or not os.path.isfile(BASE_FOLDER+model_name+'.h5'):\n",
    "    model.fit(x_train, y_train, epochs = 150, validation_data = (x_test, y_test), callbacks=callbacks)\n",
    "    # Save the model.\n",
    "    model.save(BASE_FOLDER+model_name+'.h5')\n",
    "else:\n",
    "    # Load the model.\n",
    "    model = load_model(BASE_FOLDER+model_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate it.\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('loss {} accuracy {}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction.\n",
    "img_index = 0\n",
    "img = X[img_index]\n",
    "predictions = model.predict(np.array([img]))\n",
    "prediction = np.argmax(predictions)\n",
    "\n",
    "print('Predicted: ', predictions[0])\n",
    "print('Real: ', Y[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "# Transform Pascal VOC format dataset to TFRecord\n",
    "origin_dir = '../datasets/yolo_training/PTL_Dataset_876x657'\n",
    "output_path = 'dataset.tfrecord'\n",
    "label_map_path = 'dataset_label_map.pbtxt'\n",
    "dataset.pascal_voc_to_tfrecord(origin_dir, output_path, label_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create an input pipeline.\n",
    "record_dataset_path = 'dataset.tfrecord'\n",
    "dataset = tf.data.TFRecordDataset(record_dataset_path)\n",
    "raw_example = next(iter(dataset))\n",
    "parsed = tf.train.Example.FromString(raw_example.numpy())\n",
    "\n",
    "feature = parsed.features.feature\n",
    "print(feature)\n",
    "raw_img = feature['image/encoded'].bytes_list.value[0]\n",
    "img = tf.image.decode_png(raw_img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from keras_yolo3.yolo3.model import preprocess_true_boxes\n",
    "\n",
    "def get_yolo3_anchors():\n",
    "    anchors = '10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326'\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "def get_classes():\n",
    "    label_map_path = 'dataset_label_map.pbtxt'\n",
    "    return dataset.get_classes(label_map_path)\n",
    "\n",
    "def read_tfrecord(example, input_shape, anchors, num_classes):\n",
    "    features = {\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/object/bbox/xmin': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'image/object/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        \n",
    "    }\n",
    "    # Parse the serialized data so we get a dict with our data.\n",
    "    parsed_example = tf.io.parse_single_example(serialized=example, features=features)\n",
    "    # Print features\n",
    "    sess = tf.compat.v1.InteractiveSession()\n",
    "    with sess.as_default():\n",
    "        for name, tensor in parsed_example.items():\n",
    "            print('{}: {}'.format(name, tensor.eval()))\n",
    "    print(parsed_example)\n",
    "\n",
    "    image_data = parsed_example['image/encoded']\n",
    "    x_min = parsed_example['image/object/bbox/xmin']\n",
    "    y_min = parsed_example['image/object/bbox/ymin']\n",
    "    x_max = parsed_example['image/object/bbox/xmax']\n",
    "    y_max = parsed_example['image/object/bbox/ymax']\n",
    "    class_id = parsed_example['image/object/class/label']\n",
    "    print(class_id.get_shape())\n",
    "    if tf.executing_eagerly():\n",
    "        print(class_id.numpy())\n",
    "    else:\n",
    "        print(class_id) \n",
    "        with tf.InteractiveSession() as sess:\n",
    "            print(class_id.eval()) \n",
    "    batch_size = len(class_id)\n",
    "    print('Gets here')\n",
    "    image_data = []\n",
    "    box_data = []\n",
    "    for i in range(batch_size):\n",
    "        annotation = [x_min[i], y_min[i], x_max[i], y_max[i], class_id[i]]\n",
    "        image, box = utils.get_random_data(image_data, annotation, input_shape, random=True)\n",
    "        image_data.append(image)\n",
    "        box_data.append(box)\n",
    "    image_data = np.array(image_data)\n",
    "    box_data = np.array(box_data)\n",
    "    y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "    return [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def get_dataset():\n",
    "    # Create an input pipeline.\n",
    "    record_dataset_path = 'dataset.tfrecord'\n",
    "    dataset = tf.data.TFRecordDataset(record_dataset_path)\n",
    "    input_shape = (576, 768) # multiple of 32, hw\n",
    "    anchors = get_yolo3_anchors()\n",
    "    num_classes = len(get_classes())\n",
    "    #dataset = dataset.shuffle(5000).batch(32)\n",
    "    dataset = dataset.map(lambda x: read_tfrecord(x, input_shape, anchors, num_classes))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "\n",
    "data_path = '../datasets/yolo_training/PTL_Dataset_876x657'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "labels = []\n",
    "try:\n",
    "    os.chdir(data_path)\n",
    "except OSError:\n",
    "    print('Could not change directory')\n",
    "for file in glob.glob(\"*.xml\"):\n",
    "    root = ET.parse(file).getroot()\n",
    "    image_file = root.findtext('filename')\n",
    "    for label in root.findall('object'):\n",
    "        name = label.findtext('name')\n",
    "        if name not in labels:\n",
    "            labels.append(name)\n",
    "        xmin = int(label.find('bndbox').findtext('xmin'))\n",
    "        ymin = int(label.find('bndbox').findtext('ymin'))\n",
    "        xmax = int(label.find('bndbox').findtext('xmax'))\n",
    "        ymax = int(label.find('bndbox').findtext('ymax'))\n",
    "        img = Image.open(image_file)\n",
    "        img = np.asarray(img).flatten().tolist()\n",
    "        X.append(img)\n",
    "        Y.append([xmin, ymin, xmax, ymax, labels.index(name)])\n",
    "print('All loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X[0]))\n",
    "sample = X[0]\n",
    "print(Y[0])\n",
    "\n",
    "# show image\n",
    "imgplot = plt.imshow(np.asarray(sample).reshape(657, 876, 3))\n",
    "plt.show()\n",
    "\n",
    "# Split dataset, 90% train and 10% test.\n",
    "split_1 = int(0.9 * len(X))\n",
    "\n",
    "x_train = X[:split_1]\n",
    "y_train = Y[:split_1]\n",
    "x_test = X[split_1:]\n",
    "y_test = Y[split_1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 576, 768, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 576, 768, 32) 864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_0 (BatchNormalization)    (None, 576, 768, 32) 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_0 (LeakyReLU)             (None, 576, 768, 32) 0           bnorm_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 577, 769, 32) 0           leaky_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 288, 384, 64) 18432       zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_1 (BatchNormalization)    (None, 288, 384, 64) 256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_1 (LeakyReLU)             (None, 288, 384, 64) 0           bnorm_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 288, 384, 32) 2048        leaky_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_2 (BatchNormalization)    (None, 288, 384, 32) 128         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_2 (LeakyReLU)             (None, 288, 384, 32) 0           bnorm_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 288, 384, 64) 18432       leaky_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_3 (BatchNormalization)    (None, 288, 384, 64) 256         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_3 (LeakyReLU)             (None, 288, 384, 64) 0           bnorm_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 288, 384, 64) 0           leaky_1[0][0]                    \n",
      "                                                                 leaky_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 289, 385, 64) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 144, 192, 128 73728       zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_5 (BatchNormalization)    (None, 144, 192, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_5 (LeakyReLU)             (None, 144, 192, 128 0           bnorm_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 144, 192, 64) 8192        leaky_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_6 (BatchNormalization)    (None, 144, 192, 64) 256         conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_6 (LeakyReLU)             (None, 144, 192, 64) 0           bnorm_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 144, 192, 128 73728       leaky_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_7 (BatchNormalization)    (None, 144, 192, 128 512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_7 (LeakyReLU)             (None, 144, 192, 128 0           bnorm_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 144, 192, 128 0           leaky_5[0][0]                    \n",
      "                                                                 leaky_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 144, 192, 64) 8192        add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_9 (BatchNormalization)    (None, 144, 192, 64) 256         conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_9 (LeakyReLU)             (None, 144, 192, 64) 0           bnorm_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 144, 192, 128 73728       leaky_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_10 (BatchNormalization)   (None, 144, 192, 128 512         conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_10 (LeakyReLU)            (None, 144, 192, 128 0           bnorm_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 144, 192, 128 0           add_93[0][0]                     \n",
      "                                                                 leaky_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 145, 193, 128 0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 72, 96, 256)  294912      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_12 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_12 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 72, 96, 128)  32768       leaky_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_13 (BatchNormalization)   (None, 72, 96, 128)  512         conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_13 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 72, 96, 256)  294912      leaky_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_14 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_14 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 72, 96, 256)  0           leaky_12[0][0]                   \n",
      "                                                                 leaky_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 72, 96, 128)  32768       add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_16 (BatchNormalization)   (None, 72, 96, 128)  512         conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_16 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 72, 96, 256)  294912      leaky_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_17 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_17 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 72, 96, 256)  0           add_95[0][0]                     \n",
      "                                                                 leaky_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 72, 96, 128)  32768       add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_19 (BatchNormalization)   (None, 72, 96, 128)  512         conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_19 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 72, 96, 256)  294912      leaky_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_20 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_20 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 72, 96, 256)  0           add_96[0][0]                     \n",
      "                                                                 leaky_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 72, 96, 128)  32768       add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_22 (BatchNormalization)   (None, 72, 96, 128)  512         conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_22 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 72, 96, 256)  294912      leaky_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_23 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_23 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 72, 96, 256)  0           add_97[0][0]                     \n",
      "                                                                 leaky_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_25 (Conv2D)                (None, 72, 96, 128)  32768       add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_25 (BatchNormalization)   (None, 72, 96, 128)  512         conv_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_25 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_26 (Conv2D)                (None, 72, 96, 256)  294912      leaky_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_26 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_26 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 72, 96, 256)  0           add_98[0][0]                     \n",
      "                                                                 leaky_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_28 (Conv2D)                (None, 72, 96, 128)  32768       add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_28 (BatchNormalization)   (None, 72, 96, 128)  512         conv_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_28 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_29 (Conv2D)                (None, 72, 96, 256)  294912      leaky_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_29 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_29 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 72, 96, 256)  0           add_99[0][0]                     \n",
      "                                                                 leaky_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_31 (Conv2D)                (None, 72, 96, 128)  32768       add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_31 (BatchNormalization)   (None, 72, 96, 128)  512         conv_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_31 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_32 (Conv2D)                (None, 72, 96, 256)  294912      leaky_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_32 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_32 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 72, 96, 256)  0           add_100[0][0]                    \n",
      "                                                                 leaky_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_34 (Conv2D)                (None, 72, 96, 128)  32768       add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_34 (BatchNormalization)   (None, 72, 96, 128)  512         conv_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_34 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_35 (Conv2D)                (None, 72, 96, 256)  294912      leaky_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_35 (BatchNormalization)   (None, 72, 96, 256)  1024        conv_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_35 (LeakyReLU)            (None, 72, 96, 256)  0           bnorm_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 72, 96, 256)  0           add_101[0][0]                    \n",
      "                                                                 leaky_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 73, 97, 256)  0           add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_37 (Conv2D)                (None, 36, 48, 512)  1179648     zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_37 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_37 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_38 (Conv2D)                (None, 36, 48, 256)  131072      leaky_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_38 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_38 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_39 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_39 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_39 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 36, 48, 512)  0           leaky_37[0][0]                   \n",
      "                                                                 leaky_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_41 (Conv2D)                (None, 36, 48, 256)  131072      add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_41 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_41[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_41 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_42 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_42 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_42[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_42 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_104 (Add)                   (None, 36, 48, 512)  0           add_103[0][0]                    \n",
      "                                                                 leaky_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_44 (Conv2D)                (None, 36, 48, 256)  131072      add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_44 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_44[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_44 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_45 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_45 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_45[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_45 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_105 (Add)                   (None, 36, 48, 512)  0           add_104[0][0]                    \n",
      "                                                                 leaky_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_47 (Conv2D)                (None, 36, 48, 256)  131072      add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_47 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_47[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_47 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_48 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_48 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_48[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_48 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_106 (Add)                   (None, 36, 48, 512)  0           add_105[0][0]                    \n",
      "                                                                 leaky_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_50 (Conv2D)                (None, 36, 48, 256)  131072      add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_50 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_50[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_50 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_51 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_51 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_51[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_51 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 36, 48, 512)  0           add_106[0][0]                    \n",
      "                                                                 leaky_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_53 (Conv2D)                (None, 36, 48, 256)  131072      add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_53 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_53[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_53 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_54 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_54 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_54[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_54 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 36, 48, 512)  0           add_107[0][0]                    \n",
      "                                                                 leaky_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_56 (Conv2D)                (None, 36, 48, 256)  131072      add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_56 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_56[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_56 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_57 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_57 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_57[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_57 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 36, 48, 512)  0           add_108[0][0]                    \n",
      "                                                                 leaky_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_59 (Conv2D)                (None, 36, 48, 256)  131072      add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_59 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_59[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_59 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_60 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_60 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_60[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_60 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 36, 48, 512)  0           add_109[0][0]                    \n",
      "                                                                 leaky_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 37, 49, 512)  0           add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_62 (Conv2D)                (None, 18, 24, 1024) 4718592     zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_62 (BatchNormalization)   (None, 18, 24, 1024) 4096        conv_62[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_62 (LeakyReLU)            (None, 18, 24, 1024) 0           bnorm_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_63 (Conv2D)                (None, 18, 24, 512)  524288      leaky_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_63 (BatchNormalization)   (None, 18, 24, 512)  2048        conv_63[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_63 (LeakyReLU)            (None, 18, 24, 512)  0           bnorm_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_64 (Conv2D)                (None, 18, 24, 1024) 4718592     leaky_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_64 (BatchNormalization)   (None, 18, 24, 1024) 4096        conv_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_64 (LeakyReLU)            (None, 18, 24, 1024) 0           bnorm_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 18, 24, 1024) 0           leaky_62[0][0]                   \n",
      "                                                                 leaky_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_66 (Conv2D)                (None, 18, 24, 512)  524288      add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_66 (BatchNormalization)   (None, 18, 24, 512)  2048        conv_66[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_66 (LeakyReLU)            (None, 18, 24, 512)  0           bnorm_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_67 (Conv2D)                (None, 18, 24, 1024) 4718592     leaky_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_67 (BatchNormalization)   (None, 18, 24, 1024) 4096        conv_67[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_67 (LeakyReLU)            (None, 18, 24, 1024) 0           bnorm_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 18, 24, 1024) 0           add_111[0][0]                    \n",
      "                                                                 leaky_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_69 (Conv2D)                (None, 18, 24, 512)  524288      add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_69 (BatchNormalization)   (None, 18, 24, 512)  2048        conv_69[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_69 (LeakyReLU)            (None, 18, 24, 512)  0           bnorm_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_70 (Conv2D)                (None, 18, 24, 1024) 4718592     leaky_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_70 (BatchNormalization)   (None, 18, 24, 1024) 4096        conv_70[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_70 (LeakyReLU)            (None, 18, 24, 1024) 0           bnorm_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 18, 24, 1024) 0           add_112[0][0]                    \n",
      "                                                                 leaky_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_72 (Conv2D)                (None, 18, 24, 512)  524288      add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_72 (BatchNormalization)   (None, 18, 24, 512)  2048        conv_72[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_72 (LeakyReLU)            (None, 18, 24, 512)  0           bnorm_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_73 (Conv2D)                (None, 18, 24, 1024) 4718592     leaky_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_73 (BatchNormalization)   (None, 18, 24, 1024) 4096        conv_73[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_73 (LeakyReLU)            (None, 18, 24, 1024) 0           bnorm_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 18, 24, 1024) 0           add_113[0][0]                    \n",
      "                                                                 leaky_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_75 (Conv2D)                (None, 18, 24, 512)  524288      add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_75 (BatchNormalization)   (None, 18, 24, 512)  2048        conv_75[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_75 (LeakyReLU)            (None, 18, 24, 512)  0           bnorm_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_76 (Conv2D)                (None, 18, 24, 1024) 4718592     leaky_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_76 (BatchNormalization)   (None, 18, 24, 1024) 4096        conv_76[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_76 (LeakyReLU)            (None, 18, 24, 1024) 0           bnorm_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_77 (Conv2D)                (None, 18, 24, 512)  524288      leaky_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_77 (BatchNormalization)   (None, 18, 24, 512)  2048        conv_77[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_77 (LeakyReLU)            (None, 18, 24, 512)  0           bnorm_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_78 (Conv2D)                (None, 18, 24, 1024) 4718592     leaky_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_78 (BatchNormalization)   (None, 18, 24, 1024) 4096        conv_78[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_78 (LeakyReLU)            (None, 18, 24, 1024) 0           bnorm_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_79 (Conv2D)                (None, 18, 24, 512)  524288      leaky_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_79 (BatchNormalization)   (None, 18, 24, 512)  2048        conv_79[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_79 (LeakyReLU)            (None, 18, 24, 512)  0           bnorm_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_84 (Conv2D)                (None, 18, 24, 256)  131072      leaky_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_84 (BatchNormalization)   (None, 18, 24, 256)  1024        conv_84[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_84 (LeakyReLU)            (None, 18, 24, 256)  0           bnorm_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 36, 48, 256)  0           leaky_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 36, 48, 768)  0           up_sampling2d_8[0][0]            \n",
      "                                                                 add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_87 (Conv2D)                (None, 36, 48, 256)  196608      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_87 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_87[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_87 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_88 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_88 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_88[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_88 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_89 (Conv2D)                (None, 36, 48, 256)  131072      leaky_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_89 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_89[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_89 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_90 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_90 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_90[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_90 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_91 (Conv2D)                (None, 36, 48, 256)  131072      leaky_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_91 (BatchNormalization)   (None, 36, 48, 256)  1024        conv_91[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_91 (LeakyReLU)            (None, 36, 48, 256)  0           bnorm_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_96 (Conv2D)                (None, 36, 48, 128)  32768       leaky_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_96 (BatchNormalization)   (None, 36, 48, 128)  512         conv_96[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_96 (LeakyReLU)            (None, 36, 48, 128)  0           bnorm_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 72, 96, 128)  0           leaky_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 72, 96, 384)  0           up_sampling2d_9[0][0]            \n",
      "                                                                 add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_99 (Conv2D)                (None, 72, 96, 128)  49152       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_99 (BatchNormalization)   (None, 72, 96, 128)  512         conv_99[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_99 (LeakyReLU)            (None, 72, 96, 128)  0           bnorm_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_100 (Conv2D)               (None, 72, 96, 256)  294912      leaky_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_100 (BatchNormalization)  (None, 72, 96, 256)  1024        conv_100[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_100 (LeakyReLU)           (None, 72, 96, 256)  0           bnorm_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_101 (Conv2D)               (None, 72, 96, 128)  32768       leaky_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_101 (BatchNormalization)  (None, 72, 96, 128)  512         conv_101[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_101 (LeakyReLU)           (None, 72, 96, 128)  0           bnorm_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_102 (Conv2D)               (None, 72, 96, 256)  294912      leaky_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_102 (BatchNormalization)  (None, 72, 96, 256)  1024        conv_102[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_102 (LeakyReLU)           (None, 72, 96, 256)  0           bnorm_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_103 (Conv2D)               (None, 72, 96, 128)  32768       leaky_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_103 (BatchNormalization)  (None, 72, 96, 128)  512         conv_103[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_103 (LeakyReLU)           (None, 72, 96, 128)  0           bnorm_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_80 (Conv2D)                (None, 18, 24, 1024) 4718592     leaky_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_92 (Conv2D)                (None, 36, 48, 512)  1179648     leaky_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_104 (Conv2D)               (None, 72, 96, 256)  294912      leaky_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_80 (BatchNormalization)   (None, 18, 24, 1024) 4096        conv_80[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_92 (BatchNormalization)   (None, 36, 48, 512)  2048        conv_92[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bnorm_104 (BatchNormalization)  (None, 72, 96, 256)  1024        conv_104[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_80 (LeakyReLU)            (None, 18, 24, 1024) 0           bnorm_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_92 (LeakyReLU)            (None, 36, 48, 512)  0           bnorm_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_104 (LeakyReLU)           (None, 72, 96, 256)  0           bnorm_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_81 (Conv2D)                (None, 18, 24, 255)  261375      leaky_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_93 (Conv2D)                (None, 36, 48, 255)  130815      leaky_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_105 (Conv2D)               (None, 72, 96, 255)  65535       leaky_104[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 62,001,757\n",
      "Trainable params: 61,949,149\n",
      "Non-trainable params: 52,608\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "in converted code:\n\n    /tmp/xpython_6327/1080054382.py:70 None  *\n        dataset = dataset.map(lambda x: read_tfrecord(x, input_shape, anchors, num_classes))\n    /tmp/xpython_6327/1080054382.py:32 read_tfrecord  *\n        print('{}: {}'.format(name, tensor.eval()))\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:790 eval\n        return _eval_using_default_session(self, feed_dict, self.graph, session)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:5312 _eval_using_default_session\n        return session.run(tensors, feed_dict)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:960 run\n        run_metadata_ptr)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1183 _run\n        feed_dict_tensor, options, run_metadata)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1361 _do_run\n        run_metadata)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1386 _do_call\n        raise type(e)(node_def, op, message)\n\n    InvalidArgumentError: You must feed a value for placeholder tensor 'args_0' with dtype string\n    \t [[node args_0 (defined at /tmp/xpython_6327/1080054382.py:70) ]]\n    \n    Original stack trace for 'args_0':\n      File \"<string>\", line 2, in <module>\n      File \"/tmp/xpython_6327/3082474432.py\", line 137, in <module>\n        dataset = get_dataset()\n      File \"/tmp/xpython_6327/1080054382.py\", line 70, in get_dataset\n        dataset = dataset.map(lambda x: read_tfrecord(x, input_shape, anchors, num_classes))\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1588, in map\n        return MapDataset(self, map_func, preserve_cardinality=True)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3888, in __init__\n        use_legacy_function=use_legacy_function)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3147, in __init__\n        self._function = wrapper_fn._get_concrete_function_internal()\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2395, in _get_concrete_function_internal\n        *args, **kwargs)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\n        graph_function, _, _ = self._maybe_define_function(args, kwargs)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\n        capture_by_value=self._capture_by_value),\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 898, in func_graph_from_py_func\n        args, arg_names, flat_shapes=arg_shapes)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 1127, in _get_defun_inputs_from_args\n        args, names, structure=args, flat_shapes=flat_shapes)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 1207, in _get_defun_inputs\n        name=requested_name)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/graph_only_ops.py\", line 38, in graph_placeholder\n        attrs={\"dtype\": dtype_value, \"shape\": shape}, name=name)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 595, in _create_op_internal\n        compute_device)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n        op_def=op_def)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n        self._traceback = tf_stack.extract_stack()\n    \n\n\nOriginal stack trace for 'args_0':\n  File \"<string>\", line 2, in <module>\n  File \"/tmp/xpython_6327/3082474432.py\", line 137, in <module>\n    dataset = get_dataset()\n  File \"/tmp/xpython_6327/1080054382.py\", line 70, in get_dataset\n    dataset = dataset.map(lambda x: read_tfrecord(x, input_shape, anchors, num_classes))\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1588, in map\n    return MapDataset(self, map_func, preserve_cardinality=True)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3888, in __init__\n    use_legacy_function=use_legacy_function)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3147, in __init__\n    self._function = wrapper_fn._get_concrete_function_internal()\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2395, in _get_concrete_function_internal\n    *args, **kwargs)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\n    capture_by_value=self._capture_by_value),\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 898, in func_graph_from_py_func\n    args, arg_names, flat_shapes=arg_shapes)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 1127, in _get_defun_inputs_from_args\n    args, names, structure=args, flat_shapes=flat_shapes)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 1207, in _get_defun_inputs\n    name=requested_name)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/graph_only_ops.py\", line 38, in graph_placeholder\n    attrs={\"dtype\": dtype_value, \"shape\": shape}, name=name)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 595, in _create_op_internal\n    compute_device)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "In  \u001b[0;34m[10]\u001b[0m:\nLine \u001b[0;34m137\u001b[0m:   dataset = get_dataset()\n",
      "In  \u001b[0;34m[3]\u001b[0m:\nLine \u001b[0;34m70\u001b[0m:    dataset = dataset.map(\u001b[34mlambda\u001b[39;49;00m x: read_tfrecord(x, input_shape, anchors, num_classes))\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m, in \u001b[0;32mmap\u001b[0m:\nLine \u001b[0;34m1588\u001b[0m:  \u001b[34mreturn\u001b[39;49;00m MapDataset(\u001b[36mself\u001b[39;49;00m, map_func, preserve_cardinality=\u001b[34mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m, in \u001b[0;32m__init__\u001b[0m:\nLine \u001b[0;34m3888\u001b[0m:  use_legacy_function=use_legacy_function)\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m, in \u001b[0;32m__init__\u001b[0m:\nLine \u001b[0;34m3147\u001b[0m:  \u001b[36mself\u001b[39;49;00m._function = wrapper_fn._get_concrete_function_internal()\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m, in \u001b[0;32m_get_concrete_function_internal\u001b[0m:\nLine \u001b[0;34m2395\u001b[0m:  *args, **kwargs)\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m, in \u001b[0;32m_get_concrete_function_internal_garbage_collected\u001b[0m:\nLine \u001b[0;34m2389\u001b[0m:  graph_function, _, _ = \u001b[36mself\u001b[39;49;00m._maybe_define_function(args, kwargs)\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m, in \u001b[0;32m_maybe_define_function\u001b[0m:\nLine \u001b[0;34m2703\u001b[0m:  graph_function = \u001b[36mself\u001b[39;49;00m._create_graph_function(args, kwargs)\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m, in \u001b[0;32m_create_graph_function\u001b[0m:\nLine \u001b[0;34m2593\u001b[0m:  capture_by_value=\u001b[36mself\u001b[39;49;00m._capture_by_value),\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m, in \u001b[0;32mfunc_graph_from_py_func\u001b[0m:\nLine \u001b[0;34m978\u001b[0m:   func_outputs = python_func(*func_args, **func_kwargs)\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m, in \u001b[0;32mwrapper_fn\u001b[0m:\nLine \u001b[0;34m3140\u001b[0m:  ret = _wrapper_helper(*args)\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m, in \u001b[0;32m_wrapper_helper\u001b[0m:\nLine \u001b[0;34m3082\u001b[0m:  ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n",
      "File \u001b[0;34m/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m, in \u001b[0;32mwrapper\u001b[0m:\nLine \u001b[0;34m237\u001b[0m:   \u001b[34mraise\u001b[39;49;00m e.ag_error_metadata.to_exception(e)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: in converted code:\n\n    /tmp/xpython_6327/1080054382.py:70 None  *\n        dataset = dataset.map(lambda x: read_tfrecord(x, input_shape, anchors, num_classes))\n    /tmp/xpython_6327/1080054382.py:32 read_tfrecord  *\n        print('{}: {}'.format(name, tensor.eval()))\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:790 eval\n        return _eval_using_default_session(self, feed_dict, self.graph, session)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:5312 _eval_using_default_session\n        return session.run(tensors, feed_dict)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:960 run\n        run_metadata_ptr)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1183 _run\n        feed_dict_tensor, options, run_metadata)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1361 _do_run\n        run_metadata)\n    /home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py:1386 _do_call\n        raise type(e)(node_def, op, message)\n\n    InvalidArgumentError: You must feed a value for placeholder tensor 'args_0' with dtype string\n    \t [[node args_0 (defined at /tmp/xpython_6327/1080054382.py:70) ]]\n    \n    Original stack trace for 'args_0':\n      File \"<string>\", line 2, in <module>\n      File \"/tmp/xpython_6327/3082474432.py\", line 137, in <module>\n        dataset = get_dataset()\n      File \"/tmp/xpython_6327/1080054382.py\", line 70, in get_dataset\n        dataset = dataset.map(lambda x: read_tfrecord(x, input_shape, anchors, num_classes))\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1588, in map\n        return MapDataset(self, map_func, preserve_cardinality=True)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3888, in __init__\n        use_legacy_function=use_legacy_function)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3147, in __init__\n        self._function = wrapper_fn._get_concrete_function_internal()\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2395, in _get_concrete_function_internal\n        *args, **kwargs)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\n        graph_function, _, _ = self._maybe_define_function(args, kwargs)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\n        capture_by_value=self._capture_by_value),\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 898, in func_graph_from_py_func\n        args, arg_names, flat_shapes=arg_shapes)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 1127, in _get_defun_inputs_from_args\n        args, names, structure=args, flat_shapes=flat_shapes)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 1207, in _get_defun_inputs\n        name=requested_name)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/graph_only_ops.py\", line 38, in graph_placeholder\n        attrs={\"dtype\": dtype_value, \"shape\": shape}, name=name)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 595, in _create_op_internal\n        compute_device)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n        op_def=op_def)\n      File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n        self._traceback = tf_stack.extract_stack()\n    \n\n\nOriginal stack trace for 'args_0':\n  File \"<string>\", line 2, in <module>\n  File \"/tmp/xpython_6327/3082474432.py\", line 137, in <module>\n    dataset = get_dataset()\n  File \"/tmp/xpython_6327/1080054382.py\", line 70, in get_dataset\n    dataset = dataset.map(lambda x: read_tfrecord(x, input_shape, anchors, num_classes))\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1588, in map\n    return MapDataset(self, map_func, preserve_cardinality=True)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3888, in __init__\n    use_legacy_function=use_legacy_function)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3147, in __init__\n    self._function = wrapper_fn._get_concrete_function_internal()\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2395, in _get_concrete_function_internal\n    *args, **kwargs)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\n    capture_by_value=self._capture_by_value),\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 898, in func_graph_from_py_func\n    args, arg_names, flat_shapes=arg_shapes)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 1127, in _get_defun_inputs_from_args\n    args, names, structure=args, flat_shapes=flat_shapes)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 1207, in _get_defun_inputs\n    name=requested_name)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/graph_only_ops.py\", line 38, in graph_placeholder\n    attrs={\"dtype\": dtype_value, \"shape\": shape}, name=name)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 595, in _create_op_internal\n    compute_device)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"/home/eduard/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# create a YOLOv3 Keras model and save it to file\n",
    "# based on https://github.com/experiencor/keras-yolo3\n",
    "import struct\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Add, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def _conv_block(inp, convs, skip=True):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "        x = Conv2D(conv['filter'],\n",
    "                   conv['kernel'],\n",
    "                   strides=conv['stride'],\n",
    "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "                   name='conv_' + str(conv['layer_idx']),\n",
    "                   use_bias=False if conv['bnorm'] else True)(x)\n",
    "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "    return Add()([skip_connection, x]) if skip else x\n",
    "\n",
    "def make_yolov3_model(input_shape = None):\n",
    "    if input_shape:\n",
    "        input_image = Input(shape=input_shape)\n",
    "    else:\n",
    "        input_image = Input(shape=(None, None, 3))\n",
    "    # Layer  0 => 4\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "    # Layer  5 => 8\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "    # Layer  9 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "    # Layer 12 => 15\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "    # Layer 16 => 36\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "    skip_36 = x\n",
    "    # Layer 37 => 40\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "    # Layer 41 => 61\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "    skip_61 = x\n",
    "    # Layer 62 => 65\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "    # Layer 66 => 74\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "    # Layer 75 => 79\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "    # Layer 80 => 82\n",
    "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "    # Layer 83 => 86\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = Concatenate()([x, skip_61])\n",
    "    # Layer 87 => 91\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "    # Layer 92 => 94\n",
    "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "    # Layer 95 => 98\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = Concatenate()([x, skip_36])\n",
    "    # Layer 99 => 106\n",
    "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
    "    return model\n",
    "\n",
    "BASE_FOLDER = './'\n",
    "retrain_models = False\n",
    "input_shape = (576, 768, 3)\n",
    "\n",
    "# Define the model.\n",
    "model_name = 'yolo_v3'\n",
    "model = make_yolov3_model(input_shape)\n",
    "model.compile(metrics=['accuracy'], loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Save checkpoints to get the best weights from all epochs, same name for all, to keep the best checkpoint.\n",
    "filename = BASE_FOLDER+model_name+'checkpoint.hdf5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "#def generator_from_array(x_train, y_train):\n",
    "#    while 1:\n",
    "#        for i in range(len(x_train)):\n",
    "#            yield (x_train[i], [y_train[i], y_train[i], y_train[i]])\n",
    "\n",
    "dataset = get_dataset()\n",
    "\n",
    "# Fit model.\n",
    "if retrain_models or not os.path.isfile(BASE_FOLDER+model_name+'.h5'):\n",
    "    model.fit(dataset, epochs = 150, callbacks=callbacks)\n",
    "    # Save the model.\n",
    "    model.save(BASE_FOLDER+model_name+'.h5')\n",
    "else:\n",
    "    # Load the model.\n",
    "    model = load_model(BASE_FOLDER+model_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.int32>\n",
      "Dummy function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.int32>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function _locked_settrace at 0x7f0fe2d73440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: local variable 'kill' referenced before assignment\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy function\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import ptvsd\n",
    "\n",
    "def read_tfrecord(x):\n",
    "    ptvsd.debug_this_thread()\n",
    "    print('Dummy function')\n",
    "    return x\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "print(dataset)\n",
    "dataset = dataset.map(lambda x: read_tfrecord(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 7], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "@tf.function\n",
    "def f(x, y):\n",
    "    print('Operate')\n",
    "    return x ** 2 + y\n",
    "\n",
    "x = tf.constant([2, 3])\n",
    "y = tf.constant([3, -2])\n",
    "f(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
